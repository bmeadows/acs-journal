insert into review values (13, 57, 'related', 'Highly related', "This paper addresses interactions between and the interoperability of multiple learning mechanisms in a single cognitive architecture. The learning concerns operations on knowledge rather than low level statistical rewards structures. The paper takes a specific cognitve systems perspective.");
insert into review values (13, 57, 'extension', 'Substantial extension', "The research extends the ICARUS architecture from a uniform learning mechanism to a multistrategy learner. The research not only adds new learning methods, but it investigates the way multiple methods enhance learning through their interaction. The cached beliefs from observation enable learning on new skills from problem solving for example.");
insert into review values (13, 57, 'claims', 'Clear claims', "The claims are modest although clearly stated. The claim (although not stated this way specifically) is that cognitive systems benefit from heterogeneous learning as opposed to unified monolithic learning. ");
insert into review values (13, 57, 'convincing', 'Very convincing', "The evidence presented here is compelling, although somewhat preliminary. The research is encouraging and should be extended in the future. The paper would benefit from a statement on how the authors intend to follow up this work.");
insert into review values (13, 57, 'effective', 'Somewhat effective', "The language in this paper is mainly clear, but the reader has to work at times to infer some of the technical details. One helpful suggestion is to change Figure 1 so that it corresponds to one of the three complexity levels in the experiment. Also the description of learning from observation (paragraph 3 in intro) is confusing to the reader at that point in the paper. Additionally the section on 'Learning from Constraint Violations' needs an example. In its present form, it is too opaque. Table 3 in the current context is not helpful to the reader. See below for further suggestions. ");
insert into review values (13, 57, 'comment', '', "I do not understand how the Newell in-text citation at the beginning of paragraph 2 of the intro supports the sentence. Perhaps you meant to write '(e.g., Newell, 1990)' thus using Newell as an example.
Table 1: Out of curiosity, why is the first percept of the second concept (at ?from) instead of (self ?self location ?from)?
Page 3, col. 2, second full paragraph: '... as long as they do not contradict [delete the word 'to'] the current observations.'
Page 3, last sentence: '... carries over some of [the] previous beliefs...'
Page 4, col. 1, first full paragraph: 'The rest of [the] previous beliefs...'
Page 4, col. 1, second full paragraph: 'For example, in the definition [delete the word 'for' and add the word 'of'] (at ?location)...'
Page 4, col. 1, second full paragraph: Seems odd to add a delete list to a concept. Why do you not add a delete list to the first skill of Table 2 instead? It would benefit from (at ?from) in a delete list. 
Page 5, paragraph 4 of Experimental Setup: '...[add phrase 'using Method 1'] the agent learns the route as specific skills...'
Page 5, paragraph 6 of Experimental Setup: '...but [add phrase 'using Method 3'] it realizes that taking this route would cause a constraint violation.' By the way, does it make this realization during planning or during plan execution. I assume the latter but am not sure.
Page 5, col 2, Paragraph after fig 5: '... and it perceives only three connections ...(connected A W7) [add phrase '(see Figure 1)'].'
Page 6, Experimental Results: Descriptions in text do not match legends in Figure 6 very well. The first paragraph of the section mentions 'learning from constraint violations,' 'learning from problem solving,' and 'declaratively learning.' The legends talk about learning from successes only and learning from failures only,. Actually because declarative learning is on, I am not sure learning from failures only is accurate. I suggest that you change the legend instead. Both learning on  all three learning on; learning from success only  no learning from constraints; learning from failures only  no learning from problem solving; both learning off  declarative learning only.
Page 6, col 1, last paragraph: The last sentence  mentions that after their peaks, the two conditions are roughly the same. This is for Complexity 0, not 1 or 2, right?
In complexity 0 panel of fig 6, I do not understand why the performance of the system gets worse from trial 1 to 2.
Related and future research: Learning macro operators goes way back to STRIPS itself. See Handbook of AI, Vol. 1. pages 132-133.");
insert into review values (13, 57, 'meeting', 'Accept as talk', "");
insert into review values (13, 57, 'journal', 'Reject paper', "");