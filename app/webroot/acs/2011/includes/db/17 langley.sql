insert into review values (37, 17, 'related', 'Highly related', "It proposes three challenge problems for human-level AI.");
insert into review values (37, 17, 'extension', 'Insubstantial extension', "Not that kind of paper.");
insert into review values (37, 17, 'claims', 'Clear claims', "");
insert into review values (37, 17, 'convincing', 'Not convincing', "  I find these challenge problems unconvincing for a number of reasons:
  1. being 'compelling' is a subjective judgment.  It is probably a necessary constraint to have claims accepted, but should not be sufficient.
  2. ECA work is often, as Sidner points out, an oxymoron, in that the presentation of the agents is via a software display instead of being physically embodied.  
  3. ECA work, and virtual human work more broadly, relies heavily on the Eliza effect.  For entertainment/training purposes, this is a fine thing, and is even worth doing research to figure out how to enhance it, because believability is central to the application.  But for judging human-level AI, the Eliza effect is at best a confound and at worst a disaster, because it could raise inappropriate expectations.
  4. While the scenarios presented do offer opportunities for setting up tests of reasoning and learning, the paper instead focuses on aspects more likely to get public attention than make scientific progress.");
insert into review values (37, 17, 'effective', 'Very effective', "Very clear");
insert into review values (37, 17, 'comment', '', "");
insert into review values (37, 17, 'meeting', 'Accept as poster', "UNKNOWN: KEN FORBUS DID NOT INCLUDE RECOMMENDATIONS FOR THE SYMPOSIUM IN HIS REVIEW.");
insert into review values (37, 17, 'journal', 'Conditionally accept paper', "Shifting the focus to the scientific problems these scenarios engender would make it more valuable.  What I fear is that there are dozens of papers that can be written in this genre and they will be relatively uninformative.  Perhaps this would be best as an editorial commentary?");