insert into review values (13, 20, 'related', 'Highly related', "This paper is related to high-level cognitive functioning, because it considers reasoning about social relationships and causality. Unlike planning or problem solving which considers how to achieve physical states of the environment, the social agency problem is to plan how to achieve mental states in another agents mind. The discussion is centered upon a cognitive systems perspective as its examples are with respect to the ICARUS cognitive architecture.");
insert into review values (13, 20, 'extension', 'Substantial extension', "As mentioned above the paper presents a problem called the social agency problem which is not well studied in the cognitive science literature. The author makes a compelling case that this is a significant gap that requires attention.");
insert into review values (13, 20, 'claims', 'Clear claims', "The entire paper is very clear, the claims are well laid out, and the approach to cognitive systems stated in plain language. Following the lead of Dietterich, the author describes the challenge represented by the social agency problem, examines current approaches to the problem, uses the limitations to current approaches to set an agenda for solving the problem, and provides a clear implemented example to support the case that solutions exist.");
insert into review values (13, 20, 'convincing', 'Somewhat convincing', "The example (mentioned above) is very preliminary evidence that constitutes a proof of concept rather than mature and rigorous evidence of a total solution. The goal of the paper is to outline a significant problem, however, and to challenge the community to address the problem. This goal is as significant as those papers that present the latest in a series of incremental solutions to known or generally accepted problems.");
insert into review values (13, 20, 'effective', 'Very effective', "");
insert into review values (13, 20, 'comment', '', "On page 2 in the last paragraph of the section on Challenges of Social Agency, the author states that social agency requires a cognitive system to model the mental structures of agents and people. I believe that it also requires the system to model the social relationships and structures (e.g., teams and tribes) as well. Perhaps this is an aside, but I think that it is important. 
Col 1, Page 3, last full paragraph: 'However strong question remain...' To what questions do you refer. What supports this claim exactly?
Col 2, page 6: The italicized first sentence of #4 is confusing. This whole paragraph needs to be made more clear and re-written.
First reference, page 7: Anderson is missing his first initial (i.e., J).
I agree with the author that this problem has been ignored by much of the cognitive science and artificial intelligence communities; however, I think that the author has missed some research that does address his concerns. Joe Bates' OZ Project at CMU generated a number of relevant PhD theses that related to social cognition. See for example Reilly (1996). The project was concerned with interactive drama between humans and computational systems. The system had to reason about human relationships and plan for mental and emotional states. The work of Michael Mateas and Michael Young also fall into this category. 
The work on intent inference and plan recognition is also very relevant. See for example Bell (2001; Bell & Santos, 2002). Wilensky's (1983) work cited in the paper was an early thesis that defined the plan recognition paradigm. The task is to observe human action and to infer the goals and plans held by the observed to predict further behavior. You are also correct to see the relevance of the case-based reasoning community here. From Schank and Abelson's very early (1977) work on scripts, there was a concern with reasoning about the motivations of other agents and the mental and social causality that drove such behavior. The book even mentioned a kind of 'plan box' called D-Agency which was a strategy to accomplish a goal by convincing another agent to perform an action that achieved the goal for you. Later research on case-based explanation carried this tradition much further (see Schank & Riesbeck, 1994).
References
Bell, B. (Ed.) (2001). Proceedings of the AAAI Fall Symposia on Team Intent Inference. AAAI Technical Report FS-01-05. Menlo Park, CA: AAAI Press / The MIT Press. 

Bell, B., & Santos, E. (Eds.) (2002). Proceedings of the AAAI Fall 2002 Symposium on Intent Inference for Users, Teams, and Adversaries. AAAI Technical Report FS-02-05. Menlo Park, CA: AAAI Press / The MIT Press. 

Reilly, W. S. N. (1996). Believable social and emotional agents. PhD thesis. School of Computer Science, CMU, Pittsburgh, PA.

Schank, R. C., & Abelson, R. P. (1977). Scripts, plans, goals and understanding: An inquiry into human knowledge structures. Hillsdale, NJ: Lawrence Erlbaum Associates. 

Schank, R. C., & Riesbeck, C. (1994) Inside case-based explanation. Hillsdale, NJ: LEA.");
insert into review values (13, 20, 'meeting', 'Accept as talk', "");
insert into review values (13, 20, 'journal', 'Accept conditionally', "This may be a controversial paper to include in the journal, but I support its nomination if the author clarifies a few places mentioned in the comments above and if he makes further connection to related work.");